{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VK23-2 Qualification NLP Case 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords, gutenberg\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.chunk import ne_chunk\n",
    "import string\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "snowball_stemmer = SnowballStemmer('english')\n",
    "eng_stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pos.txt\", \"r\", encoding=\"latin-1\") as positive_file:\n",
    "    positive = positive_file.read()\n",
    "\n",
    "with open(\"neg.txt\", \"r\", encoding=\"latin-1\") as negative_file:\n",
    "    negative = negative_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return 'a'\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return 'v'\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return 'n'\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return 'r'\n",
    "    else:\n",
    "        return 'n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_words = word_tokenize(positive) + word_tokenize(negative)\n",
    "list_words = [word for word in list_words if word.lower() not in eng_stopwords]\n",
    "list_words = [word for word in list_words if word not in string.punctuation]\n",
    "list_words = [word for word in list_words if word.isalpha()]\n",
    "\n",
    "tagged = pos_tag(list_words)\n",
    "ner = ne_chunk(tagged)\n",
    "\n",
    "list_words = [wnl.lemmatize(word, get_wordnet_pos(tag)) for word, tag in tagged]\n",
    "list_words = [snowball_stemmer.stem(word) for word in list_words]\n",
    "fd = FreqDist(list_words)\n",
    "list_words = [word for word, count in fd.most_common(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_sentence = []\n",
    "for sentence in positive.split(\"\\n\"):\n",
    "    labeled_sentence.append((sentence, \"Not Spam\"))\n",
    "for sentence in negative.split(\"\\n\"):\n",
    "    labeled_sentence.append((sentence, \"Spam\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "for sent, label in labeled_sentence:\n",
    "    dict = {\"key\":\"value\"}\n",
    "    word = word_tokenize(sent)\n",
    "    for feature in list_words:\n",
    "        key = feature\n",
    "        value = feature in word\n",
    "        dict[key] = value\n",
    "    dataset.append((dict, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset Training and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(dataset)\n",
    "counter = int(len(dataset) * 0.7)\n",
    "training_data = dataset[:counter]\n",
    "testing_data = dataset[counter:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.23529411764706 %\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify import NaiveBayesClassifier,accuracy\n",
    "classifier = NaiveBayesClassifier.train(training_data)\n",
    "accuracy = accuracy(classifier, testing_data)\n",
    "print(accuracy * 100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file = open(\"model.pickle\", \"wb\")\n",
    "pickle.dump(classifier, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8823529411764706\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify import NaiveBayesClassifier,accuracy\n",
    "file = open(\"model.pickle\", \"rb\")\n",
    "classifier = pickle.load(file)\n",
    "file.close()\n",
    "accuracy = accuracy(classifier, testing_data)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpora():\n",
    "    words = gutenberg.raw('milton-paradise.txt').split()\n",
    "\n",
    "    i = 0\n",
    "    for word in words:\n",
    "        i += 1\n",
    "        synsets = wordnet.synsets(word)\n",
    "        for synset in synsets:\n",
    "            print(f\"{synset}: {synset.definition()}\")\n",
    "            for lemma in synset.lemmas():\n",
    "                print(f\"Synonym: {lemma.name()}\")\n",
    "                for antonym in lemma.antonyms():\n",
    "                    print(f\"Antonym: {antonym.name()}\")\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural Language Processing\n",
      "1. Classification\n",
      "2. View Model NER\n",
      "3. Corpora\n",
      "4. Most Informative Features\n",
      "0. Exit\n",
      "Most Informative Features\n",
      "                     txt = True             Spam : Not Sp =     39.3 : 1.0\n",
      "                    cash = True             Spam : Not Sp =     12.9 : 1.0\n",
      "                    stop = True             Spam : Not Sp =     11.5 : 1.0\n",
      "                  number = True             Spam : Not Sp =     10.7 : 1.0\n",
      "                    free = True             Spam : Not Sp =     10.1 : 1.0\n",
      "                    text = True             Spam : Not Sp =      8.5 : 1.0\n",
      "                    call = True             Spam : Not Sp =      7.8 : 1.0\n",
      "                  friend = True             Spam : Not Sp =      4.4 : 1.0\n",
      "                     min = True             Spam : Not Sp =      3.8 : 1.0\n",
      "                     pls = True             Spam : Not Sp =      3.1 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print('Natural Language Processing')\n",
    "print('1. Classification')\n",
    "print('2. View Model NER')\n",
    "print('3. Corpora')\n",
    "print('4. Most Informative Features')\n",
    "print('0. Exit')\n",
    "command = input('Enter command: ')\n",
    "\n",
    "if (command == '1'):\n",
    "    review = input(\"Input Review : \")\n",
    "    words = word_tokenize(review)\n",
    "    classifier = pickle.load(open(\"model.pickle\", \"rb\"))\n",
    "    result = classifier.classify(FreqDist(words))\n",
    "    print(result)\n",
    "elif (command == '2'):\n",
    "    print(ner)\n",
    "elif (command == '3'):\n",
    "    corpora()\n",
    "elif (command == '4'):\n",
    "    classifier = pickle.load(open(\"model.pickle\", \"rb\"))\n",
    "    print(classifier.show_most_informative_features(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
