{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 7 : Language Model (N Grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-Gram Model:\n",
      "   and  another  document  here  is  sample  third  this\n",
      "0    0        0         1     0   1       1      0     1\n",
      "1    0        1         1     1   1       0      0     0\n",
      "2    1        0         1     0   1       0      1     1\n",
      "[[0 0 0 0 1 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class NGramLanguageModel : \n",
    "    def __init__(self,n):\n",
    "        self.n = n\n",
    "        self.vectorizer = CountVectorizer(analyzer='word',ngram_range=(n,n))\n",
    "        \n",
    "    def fit_transform(self,corpus):\n",
    "        return self.vectorizer.fit_transform(corpus)\n",
    "    \n",
    "    def transform(self,corpus):\n",
    "        return self.vectorizer.transform(corpus)\n",
    "\n",
    "def calculate_cosine_similarity_matrix(matrix, query_v):\n",
    "    similarities = cosine_similarity(matrix, query_v)\n",
    "    return similarities\n",
    "\n",
    "corpus = [\n",
    "    \"This is a sample document.\",\n",
    "    \"Here is another document.\",\n",
    "    \"And this is a third document.\"\n",
    "]\n",
    "\n",
    "query = \"This is the query text\"\n",
    "\n",
    "n = 1\n",
    "document_index = 0\n",
    "\n",
    "ngram_model = NGramLanguageModel(n)\n",
    "\n",
    "matrix = ngram_model.fit_transform(corpus)\n",
    "query_v = ngram_model.transform([query])\n",
    "\n",
    "print(f\"{n}-Gram Model:\")\n",
    "data = matrix.A\n",
    " \n",
    "print(pd.DataFrame(matrix.A, columns=ngram_model.vectorizer.get_feature_names_out()))\n",
    "print(query_v.A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the query text\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a sample document.</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Here is another document.</td>\n",
       "      <td>0.353553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>And this is a third document.</td>\n",
       "      <td>0.632456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Document  Similarity\n",
       "0     This is a sample document.    0.707107\n",
       "1      Here is another document.    0.353553\n",
       "2  And this is a third document.    0.632456"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities = calculate_cosine_similarity_matrix(matrix, query_v)\n",
    "\n",
    "data = {'Document': corpus, 'Similarity': similarities.flatten()}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(query)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 8 : Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jonathanmaverick/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/jonathanmaverick/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'is', 'today', 'to', 'I', 'am', 'It', 'going', 'outside', 'Today', 'not', 'rain'}\n"
     ]
    }
   ],
   "source": [
    "first_sentence = \"It is going to rain today\"\n",
    "second_sentence = \"Today I am not going outside\"\n",
    "\n",
    "first_sentence = first_sentence.split(\" \")\n",
    "second_sentence = second_sentence.split(\" \")\n",
    "total = set(first_sentence).union(set(second_sentence))\n",
    "\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordDictA = dict.fromkeys(total, 0)\n",
    "wordDictB = dict.fromkeys(total, 0)\n",
    "\n",
    "for word in first_sentence:\n",
    "    wordDictA[word]+=1\n",
    "\n",
    "for word in second_sentence:\n",
    "    wordDictB[word]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is</th>\n",
       "      <th>today</th>\n",
       "      <th>to</th>\n",
       "      <th>I</th>\n",
       "      <th>am</th>\n",
       "      <th>It</th>\n",
       "      <th>going</th>\n",
       "      <th>outside</th>\n",
       "      <th>Today</th>\n",
       "      <th>not</th>\n",
       "      <th>rain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is  today  to  I  am  It  going  outside  Today  not  rain\n",
       "0   1      1   1  0   0   1      1        0      0    0     1\n",
       "1   0      0   0  1   1   0      1        1      1    1     0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([wordDictA, wordDictB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is</th>\n",
       "      <th>today</th>\n",
       "      <th>to</th>\n",
       "      <th>I</th>\n",
       "      <th>am</th>\n",
       "      <th>It</th>\n",
       "      <th>going</th>\n",
       "      <th>outside</th>\n",
       "      <th>Today</th>\n",
       "      <th>not</th>\n",
       "      <th>rain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         is     today        to         I        am        It     going  \\\n",
       "0  0.166667  0.166667  0.166667  0.000000  0.000000  0.166667  0.166667   \n",
       "1  0.000000  0.000000  0.000000  0.166667  0.166667  0.000000  0.166667   \n",
       "\n",
       "    outside     Today       not      rain  \n",
       "0  0.000000  0.000000  0.000000  0.166667  \n",
       "1  0.166667  0.166667  0.166667  0.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def computeTF(wordDict, doc):\n",
    "    tfDict = {}\n",
    "    corpusCount = len(doc)\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count/float(corpusCount)\n",
    "    return (tfDict)\n",
    "\n",
    "tfFirst = computeTF(wordDictA, first_sentence)\n",
    "tfSecond = computeTF(wordDictB, second_sentence)\n",
    "\n",
    "tf = pd.DataFrame([tfFirst, tfSecond])\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['today', 'I', 'It', 'going', 'outside', 'Today', 'rain']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_sentence = []\n",
    "for word in wordDictA:\n",
    "    if str(word) not in set (stopwords.words('english')):\n",
    "        filtered_sentence.append(word)\n",
    "        \n",
    "filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is</td>\n",
       "      <td>0.30103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>today</td>\n",
       "      <td>0.30103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to</td>\n",
       "      <td>0.30103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I</td>\n",
       "      <td>0.30103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>am</td>\n",
       "      <td>0.30103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>It</td>\n",
       "      <td>0.30103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>going</td>\n",
       "      <td>0.30103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>outside</td>\n",
       "      <td>0.30103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Today</td>\n",
       "      <td>0.30103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>not</td>\n",
       "      <td>0.30103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rain</td>\n",
       "      <td>0.30103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word      IDF\n",
       "0        is  0.30103\n",
       "1     today  0.30103\n",
       "2        to  0.30103\n",
       "3         I  0.30103\n",
       "4        am  0.30103\n",
       "5        It  0.30103\n",
       "6     going  0.30103\n",
       "7   outside  0.30103\n",
       "8     Today  0.30103\n",
       "9       not  0.30103\n",
       "10     rain  0.30103"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def computeIDF(docList):\n",
    "    import math\n",
    "    idfDict = {}\n",
    "    N = len(docList)\n",
    "    \n",
    "    idfDict = dict.fromkeys(docList[0].keys(), 0)\n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log10(N / (float(val) + 1))\n",
    "    \n",
    "    idf_df = pd.DataFrame(list(idfDict.items()), columns=['Word', 'IDF'])\n",
    "    \n",
    "    return idf_df\n",
    "\n",
    "idfs = computeIDF([wordDictA, wordDictB])\n",
    "idfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is</th>\n",
       "      <th>today</th>\n",
       "      <th>to</th>\n",
       "      <th>I</th>\n",
       "      <th>am</th>\n",
       "      <th>It</th>\n",
       "      <th>going</th>\n",
       "      <th>outside</th>\n",
       "      <th>Today</th>\n",
       "      <th>not</th>\n",
       "      <th>rain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         is     today        to         I        am        It     going  \\\n",
       "0  0.050172  0.050172  0.050172  0.000000  0.000000  0.050172  0.050172   \n",
       "1  0.000000  0.000000  0.000000  0.050172  0.050172  0.000000  0.050172   \n",
       "\n",
       "    outside     Today       not      rain  \n",
       "0  0.000000  0.000000  0.000000  0.050172  \n",
       "1  0.050172  0.050172  0.050172  0.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def computeTFIDF(tfbow, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfbow.items():\n",
    "        tfidf[word] = val*idfs.loc[idfs['Word'] == word, 'IDF'].values[0]\n",
    "    return tfidf\n",
    "\n",
    "idfFirst = computeTFIDF(tfFirst, idfs)\n",
    "idfSecond = computeTFIDF(tfSecond, idfs)\n",
    "\n",
    "idf = pd.DataFrame([idfFirst, idfSecond])\n",
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np \n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It is going to rain today', 'Today I am not going outside']\n"
     ]
    }
   ],
   "source": [
    "Document1 = \"It is going to rain today\"\n",
    "Document2 = \"Today I am not going outside\"\n",
    "\n",
    "Doc = [Document1, Document2]\n",
    "print(Doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 9 : Grammar Parsing with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: the cat chased the dog\n",
      "(S (NP (Det the) (N cat)) (VP (V chased) (NP (Det the) (N dog)))) \n",
      "\n",
      "              S               \n",
      "      ________|_____           \n",
      "     |              VP        \n",
      "     |         _____|___       \n",
      "     NP       |         NP    \n",
      "  ___|___     |      ___|___   \n",
      "Det      N    V    Det      N \n",
      " |       |    |     |       |  \n",
      "the     cat chased the     dog\n",
      "\n",
      "\n",
      "\n",
      "Sentence 2: i saw a cookie\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'nltk.parse.api' has no attribute 'ParserError'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 10\u001b[0m, in \u001b[0;36mdemonstrate_nlp_parsing\u001b[0;34m(sentence, grammar)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 10\u001b[0m     parses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parses:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/nltk/parse/chart.py:1474\u001b[0m, in \u001b[0;36mChartParser.parse\u001b[0;34m(self, tokens, tree_class)\u001b[0m\n\u001b[1;32m   1473\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, tokens, tree_class\u001b[38;5;241m=\u001b[39mTree):\n\u001b[0;32m-> 1474\u001b[0m     chart \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchart_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1475\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28miter\u001b[39m(chart\u001b[38;5;241m.\u001b[39mparses(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grammar\u001b[38;5;241m.\u001b[39mstart(), tree_class\u001b[38;5;241m=\u001b[39mtree_class))\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/nltk/parse/chart.py:1432\u001b[0m, in \u001b[0;36mChartParser.chart_parse\u001b[0;34m(self, tokens, trace)\u001b[0m\n\u001b[1;32m   1431\u001b[0m tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(tokens)\n\u001b[0;32m-> 1432\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_grammar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_coverage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1433\u001b[0m chart \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_chart_class(tokens)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/nltk/grammar.py:665\u001b[0m, in \u001b[0;36mCFG.check_coverage\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    664\u001b[0m missing \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mw\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m missing)\n\u001b[0;32m--> 665\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    666\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGrammar does not cover some of the \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput words: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m missing\n\u001b[1;32m    667\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Grammar does not cover some of the input words: \"'i'\".",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, sentence \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(nlp_sentences):\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSentence \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnlp_sentences[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 40\u001b[0m     \u001b[43mdemonstrate_nlp_parsing\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnlp_grammar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[15], line 17\u001b[0m, in \u001b[0;36mdemonstrate_nlp_parsing\u001b[0;34m(sentence, grammar)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m :\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo parse tree found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mParserError\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError during parsing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'nltk.parse.api' has no attribute 'ParserError'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import CFG\n",
    "from nltk.parse import ChartParser\n",
    "\n",
    "def demonstrate_nlp_parsing(sentence, grammar):\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    parser = ChartParser(grammar)\n",
    "    \n",
    "    try:\n",
    "        parses = list(parser.parse(words))\n",
    "        if parses:\n",
    "            for tree in parser.parse(sentence.split()):\n",
    "                print(tree, \"\\n\")\n",
    "                tree.pretty_print()\n",
    "        else :\n",
    "            print(\"No parse tree found\")\n",
    "    except nltk.parse.api.ParserError as e:\n",
    "        print(f\"Error during parsing {e}\")\n",
    "        \n",
    "nlp_grammar = CFG.fromstring(\"\"\"\n",
    "    S -> NP VP                   \n",
    "    NP -> Det N | Det N PP | 'I'\n",
    "    VP -> V NP | VP PP\n",
    "    PP -> P NP\n",
    "    Det -> 'the' | 'a'\n",
    "    N -> 'cat' | 'dog' | 'park' | 'cookie'\n",
    "    V -> 'chased' | 'saw' | 'ate' \n",
    "    P -> 'in' | 'on' | 'with'\n",
    "\"\"\")\n",
    "\n",
    "nlp_sentences = [\n",
    "    \"the cat chased the dog\",\n",
    "    \"i saw a cookie\",\n",
    "    \"the dog ate a cookie in the park\",\n",
    "    \"i chased the cat with the cookie\"\n",
    "]\n",
    "\n",
    "for i, sentence in enumerate(nlp_sentences):\n",
    "    print(f\"Sentence {i+1}: {nlp_sentences[i]}\")\n",
    "    demonstrate_nlp_parsing(sentence, nlp_grammar)\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
