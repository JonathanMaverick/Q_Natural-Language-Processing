{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 7 : Language Model (N Grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-Gram Model:\n",
      "   and  another  document  here  is  sample  third  this\n",
      "0    0        0         1     0   1       1      0     1\n",
      "1    0        1         1     1   1       0      0     0\n",
      "2    1        0         1     0   1       0      1     1\n",
      "[[0 0 0 0 1 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class NGramLanguageModel : \n",
    "    def __init__(self,n):\n",
    "        self.n = n\n",
    "        self.vectorizer = CountVectorizer(analyzer='word',ngram_range=(n,n))\n",
    "        \n",
    "    def fit_transform(self,corpus):\n",
    "        return self.vectorizer.fit_transform(corpus)\n",
    "    \n",
    "    def transform(self,corpus):\n",
    "        return self.vectorizer.transform(corpus)\n",
    "\n",
    "def calculate_cosine_similarity_matrix(matrix, query_v):\n",
    "    similarities = cosine_similarity(matrix, query_v)\n",
    "    return similarities\n",
    "\n",
    "corpus = [\n",
    "    \"This is a sample document.\",\n",
    "    \"Here is another document.\",\n",
    "    \"And this is a third document.\"\n",
    "]\n",
    "\n",
    "query = \"This is the query text\"\n",
    "\n",
    "n = 1\n",
    "document_index = 0\n",
    "\n",
    "ngram_model = NGramLanguageModel(n)\n",
    "\n",
    "matrix = ngram_model.fit_transform(corpus)\n",
    "query_v = ngram_model.transform([query])\n",
    "\n",
    "print(f\"{n}-Gram Model:\")\n",
    "data = matrix.A\n",
    " \n",
    "print(pd.DataFrame(matrix.A, columns=ngram_model.vectorizer.get_feature_names_out()))\n",
    "print(query_v.A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the query text\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a sample document.</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Here is another document.</td>\n",
       "      <td>0.353553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>And this is a third document.</td>\n",
       "      <td>0.632456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Document  Similarity\n",
       "0     This is a sample document.    0.707107\n",
       "1      Here is another document.    0.353553\n",
       "2  And this is a third document.    0.632456"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities = calculate_cosine_similarity_matrix(matrix, query_v)\n",
    "\n",
    "data = {'Document': corpus, 'Similarity': similarities.flatten()}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(query)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 8 : Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jonathanmaverick/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/jonathanmaverick/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'is', 'today', 'to', 'I', 'am', 'It', 'going', 'outside', 'Today', 'not', 'rain'}\n"
     ]
    }
   ],
   "source": [
    "first_sentence = \"It is going to rain today\"\n",
    "second_sentence = \"Today I am not going outside\"\n",
    "\n",
    "first_sentence = first_sentence.split(\" \")\n",
    "second_sentence = second_sentence.split(\" \")\n",
    "total = set(first_sentence).union(set(second_sentence))\n",
    "\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordDictA = dict.fromkeys(total, 0)\n",
    "wordDictB = dict.fromkeys(total, 0)\n",
    "\n",
    "for word in first_sentence:\n",
    "    wordDictA[word]+=1\n",
    "\n",
    "for word in second_sentence:\n",
    "    wordDictB[word]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is</th>\n",
       "      <th>today</th>\n",
       "      <th>to</th>\n",
       "      <th>I</th>\n",
       "      <th>am</th>\n",
       "      <th>It</th>\n",
       "      <th>going</th>\n",
       "      <th>outside</th>\n",
       "      <th>Today</th>\n",
       "      <th>not</th>\n",
       "      <th>rain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is  today  to  I  am  It  going  outside  Today  not  rain\n",
       "0   1      1   1  0   0   1      1        0      0    0     1\n",
       "1   0      0   0  1   1   0      1        1      1    1     0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([wordDictA, wordDictB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is</th>\n",
       "      <th>today</th>\n",
       "      <th>to</th>\n",
       "      <th>I</th>\n",
       "      <th>am</th>\n",
       "      <th>It</th>\n",
       "      <th>going</th>\n",
       "      <th>outside</th>\n",
       "      <th>Today</th>\n",
       "      <th>not</th>\n",
       "      <th>rain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         is     today        to         I        am        It     going  \\\n",
       "0  0.166667  0.166667  0.166667  0.000000  0.000000  0.166667  0.166667   \n",
       "1  0.000000  0.000000  0.000000  0.166667  0.166667  0.000000  0.166667   \n",
       "\n",
       "    outside     Today       not      rain  \n",
       "0  0.000000  0.000000  0.000000  0.166667  \n",
       "1  0.166667  0.166667  0.166667  0.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def computeTF(wordDict, doc):\n",
    "    tfDict = {}\n",
    "    corpusCount = len(doc)\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count/float(corpusCount)\n",
    "    return (tfDict)\n",
    "\n",
    "tfFirst = computeTF(wordDictA, first_sentence)\n",
    "tfSecond = computeTF(wordDictB, second_sentence)\n",
    "\n",
    "tf = pd.DataFrame([tfFirst, tfSecond])\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['today', 'I', 'It', 'going', 'outside', 'Today', 'rain']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_sentence = []\n",
    "for word in wordDictA:\n",
    "    if str(word) not in set (stopwords.words('english')):\n",
    "        filtered_sentence.append(word)\n",
    "        \n",
    "filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is</td>\n",
       "      <td>0.30103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>today</td>\n",
       "      <td>0.30103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to</td>\n",
       "      <td>0.30103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I</td>\n",
       "      <td>0.30103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>am</td>\n",
       "      <td>0.30103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>It</td>\n",
       "      <td>0.30103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>going</td>\n",
       "      <td>0.30103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>outside</td>\n",
       "      <td>0.30103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Today</td>\n",
       "      <td>0.30103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>not</td>\n",
       "      <td>0.30103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rain</td>\n",
       "      <td>0.30103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word      IDF\n",
       "0        is  0.30103\n",
       "1     today  0.30103\n",
       "2        to  0.30103\n",
       "3         I  0.30103\n",
       "4        am  0.30103\n",
       "5        It  0.30103\n",
       "6     going  0.30103\n",
       "7   outside  0.30103\n",
       "8     Today  0.30103\n",
       "9       not  0.30103\n",
       "10     rain  0.30103"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def computeIDF(docList):\n",
    "    import math\n",
    "    idfDict = {}\n",
    "    N = len(docList)\n",
    "    \n",
    "    idfDict = dict.fromkeys(docList[0].keys(), 0)\n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log10(N / (float(val) + 1))\n",
    "    \n",
    "    idf_df = pd.DataFrame(list(idfDict.items()), columns=['Word', 'IDF'])\n",
    "    \n",
    "    return idf_df\n",
    "\n",
    "idfs = computeIDF([wordDictA, wordDictB])\n",
    "idfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is</th>\n",
       "      <th>today</th>\n",
       "      <th>to</th>\n",
       "      <th>I</th>\n",
       "      <th>am</th>\n",
       "      <th>It</th>\n",
       "      <th>going</th>\n",
       "      <th>outside</th>\n",
       "      <th>Today</th>\n",
       "      <th>not</th>\n",
       "      <th>rain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         is     today        to         I        am        It     going  \\\n",
       "0  0.050172  0.050172  0.050172  0.000000  0.000000  0.050172  0.050172   \n",
       "1  0.000000  0.000000  0.000000  0.050172  0.050172  0.000000  0.050172   \n",
       "\n",
       "    outside     Today       not      rain  \n",
       "0  0.000000  0.000000  0.000000  0.050172  \n",
       "1  0.050172  0.050172  0.050172  0.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def computeTFIDF(tfbow, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfbow.items():\n",
    "        tfidf[word] = val*idfs.loc[idfs['Word'] == word, 'IDF'].values[0]\n",
    "    return tfidf\n",
    "\n",
    "idfFirst = computeTFIDF(tfFirst, idfs)\n",
    "idfSecond = computeTFIDF(tfSecond, idfs)\n",
    "\n",
    "idf = pd.DataFrame([idfFirst, idfSecond])\n",
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np \n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It is going to rain today', 'Today I am not going outside']\n"
     ]
    }
   ],
   "source": [
    "Document1 = \"It is going to rain today\"\n",
    "Document2 = \"Today I am not going outside\"\n",
    "\n",
    "Doc = [Document1, Document2]\n",
    "print(Doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 9 : Grammar Parsing with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: the cat chased the dog\n",
      "(S (NP (Det the) (N cat)) (VP (V chased) (NP (Det the) (N dog)))) \n",
      "\n",
      "              S               \n",
      "      ________|_____           \n",
      "     |              VP        \n",
      "     |         _____|___       \n",
      "     NP       |         NP    \n",
      "  ___|___     |      ___|___   \n",
      "Det      N    V    Det      N \n",
      " |       |    |     |       |  \n",
      "the     cat chased the     dog\n",
      "\n",
      "\n",
      "\n",
      "Sentence 2: i saw a cookie\n",
      "(S (NP i) (VP (V saw) (NP (Det a) (N cookie)))) \n",
      "\n",
      "         S                \n",
      "  _______|___              \n",
      " |           VP           \n",
      " |    _______|___          \n",
      " |   |           NP       \n",
      " |   |        ___|____     \n",
      " NP  V      Det       N   \n",
      " |   |       |        |    \n",
      " i  saw      a      cookie\n",
      "\n",
      "\n",
      "\n",
      "Sentence 3: the dog ate a cookie in the park\n",
      "(S\n",
      "  (NP (Det the) (N dog))\n",
      "  (VP\n",
      "    (VP (V ate) (NP (Det a) (N cookie)))\n",
      "    (PP (P in) (NP (Det the) (N park))))) \n",
      "\n",
      "                 S                             \n",
      "      ___________|________                      \n",
      "     |                    VP                   \n",
      "     |            ________|_________            \n",
      "     |           VP                 PP         \n",
      "     |        ___|___            ___|___        \n",
      "     NP      |       NP         |       NP     \n",
      "  ___|___    |    ___|____      |    ___|___    \n",
      "Det      N   V  Det       N     P  Det      N  \n",
      " |       |   |   |        |     |   |       |   \n",
      "the     dog ate  a      cookie  in the     park\n",
      "\n",
      "(S\n",
      "  (NP (Det the) (N dog))\n",
      "  (VP\n",
      "    (V ate)\n",
      "    (NP (Det a) (N cookie) (PP (P in) (NP (Det the) (N park)))))) \n",
      "\n",
      "                 S                         \n",
      "      ___________|____                      \n",
      "     |                VP                   \n",
      "     |        ________|_____                \n",
      "     |       |              NP             \n",
      "     |       |    __________|___            \n",
      "     |       |   |    |         PP         \n",
      "     |       |   |    |      ___|___        \n",
      "     NP      |   |    |     |       NP     \n",
      "  ___|___    |   |    |     |    ___|___    \n",
      "Det      N   V  Det   N     P  Det      N  \n",
      " |       |   |   |    |     |   |       |   \n",
      "the     dog ate  a  cookie  in the     park\n",
      "\n",
      "\n",
      "\n",
      "Sentence 4: i chased the cat with the cookie\n",
      "(S\n",
      "  (NP i)\n",
      "  (VP\n",
      "    (VP (V chased) (NP (Det the) (N cat)))\n",
      "    (PP (P with) (NP (Det the) (N cookie))))) \n",
      "\n",
      "      S                                   \n",
      "  ____|_____________                       \n",
      " |                  VP                    \n",
      " |           _______|________              \n",
      " |          VP               PP           \n",
      " |     _____|___         ____|___          \n",
      " |    |         NP      |        NP       \n",
      " |    |      ___|___    |     ___|____     \n",
      " NP   V    Det      N   P   Det       N   \n",
      " |    |     |       |   |    |        |    \n",
      " i  chased the     cat with the     cookie\n",
      "\n",
      "(S\n",
      "  (NP i)\n",
      "  (VP\n",
      "    (V chased)\n",
      "    (NP (Det the) (N cat) (PP (P with) (NP (Det the) (N cookie)))))) \n",
      "\n",
      "      S                               \n",
      "  ____|_________                       \n",
      " |              VP                    \n",
      " |     _________|___                   \n",
      " |    |             NP                \n",
      " |    |      _______|____              \n",
      " |    |     |   |        PP           \n",
      " |    |     |   |    ____|___          \n",
      " |    |     |   |   |        NP       \n",
      " |    |     |   |   |     ___|____     \n",
      " NP   V    Det  N   P   Det       N   \n",
      " |    |     |   |   |    |        |    \n",
      " i  chased the cat with the     cookie\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import CFG\n",
    "from nltk.parse import ChartParser\n",
    "\n",
    "def demonstrate_nlp_parsing(sentence, grammar):\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    parser = ChartParser(grammar)\n",
    "    \n",
    "    try:\n",
    "        parses = list(parser.parse(words))\n",
    "        if parses:\n",
    "            for tree in parser.parse(sentence.split()):\n",
    "                print(tree, \"\\n\")\n",
    "                tree.pretty_print()\n",
    "        else :\n",
    "            print(\"No parse tree found\")\n",
    "    except nltk.parse.api.ParserError as e:\n",
    "        print(f\"Error during parsing {e}\")\n",
    "        \n",
    "nlp_grammar = CFG.fromstring(\"\"\"\n",
    "    S -> NP VP                   \n",
    "    NP -> Det N | Det N PP | 'i'\n",
    "    VP -> V NP | VP PP\n",
    "    PP -> P NP\n",
    "    Det -> 'the' | 'a'\n",
    "    N -> 'cat' | 'dog' | 'park' | 'cookie'\n",
    "    V -> 'chased' | 'saw' | 'ate' \n",
    "    P -> 'in' | 'on' | 'with'\n",
    "\"\"\")\n",
    "\n",
    "nlp_sentences = [\n",
    "    \"the cat chased the dog\",\n",
    "    \"i saw a cookie\",\n",
    "    \"the dog ate a cookie in the park\",\n",
    "    \"i chased the cat with the cookie\"\n",
    "]\n",
    "\n",
    "for i, sentence in enumerate(nlp_sentences):\n",
    "    print(f\"Sentence {i+1}: {nlp_sentences[i]}\")\n",
    "    demonstrate_nlp_parsing(sentence, nlp_grammar)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse Tree: \n",
      "(S (NP (Det the) (N cat)) (VP (V chased) (NP (Det the) (N dog))))\n",
      "(S\n",
      "  (NP i)\n",
      "  (VP\n",
      "    (V chased)\n",
      "    (NP (Det the) (N cat))\n",
      "    (PP (P with) (NP (Det the) (N cookie))))) \n",
      "\n",
      "      S                                   \n",
      "  ____|_____________                       \n",
      " |                  VP                    \n",
      " |     _____________|________              \n",
      " |    |         |            PP           \n",
      " |    |         |        ____|___          \n",
      " |    |         NP      |        NP       \n",
      " |    |      ___|___    |     ___|____     \n",
      " NP   V    Det      N   P   Det       N   \n",
      " |    |     |       |   |    |        |    \n",
      " i  chased the     cat with the     cookie\n",
      "\n",
      "(S\n",
      "  (NP i)\n",
      "  (VP\n",
      "    (V chased)\n",
      "    (NP (Det the) (N cat) (PP (P with) (NP (Det the) (N cookie)))))) \n",
      "\n",
      "      S                               \n",
      "  ____|_________                       \n",
      " |              VP                    \n",
      " |     _________|___                   \n",
      " |    |             NP                \n",
      " |    |      _______|____              \n",
      " |    |     |   |        PP           \n",
      " |    |     |   |    ____|___          \n",
      " |    |     |   |   |        NP       \n",
      " |    |     |   |   |     ___|____     \n",
      " NP   V    Det  N   P   Det       N   \n",
      " |    |     |   |   |    |        |    \n",
      " i  chased the cat with the     cookie\n",
      "\n",
      "\n",
      "Extracted Information:\n",
      "Found a noun parse: the cat\n",
      "Found a verb parse: chased the dog\n",
      "Found a noun parse: the dog\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import CFG\n",
    "from nltk.parse import ChartParser\n",
    "\n",
    "def extract_information(parse_tree):\n",
    "    for subtree in parse_tree.subtrees():\n",
    "        if subtree.label() == 'NP':\n",
    "            print(f\"Found a noun parse: {' '.join(subtree.leaves())}\")\n",
    "        elif subtree.label() == 'VP':\n",
    "            print(f\"Found a verb parse: {' '.join(subtree.leaves())}\")\n",
    "            \n",
    "nlp_grammar = CFG.fromstring(\"\"\"\n",
    "    S -> NP VP\n",
    "    NP -> Det N | Det N PP | 'i' | 'I'\n",
    "    VP -> V NP | V NP PP\n",
    "    Det -> 'the' | 'a'\n",
    "    N -> 'cat' | 'dog' | 'park' | 'cookie'\n",
    "    V -> 'chased' | 'saw' | 'ate'\n",
    "    PP -> P NP\n",
    "    P -> 'in' | 'on' | 'with'\n",
    "\"\"\")\n",
    "\n",
    "nlp_sentence = \"the cat chased the dog\"\n",
    "\n",
    "words = nltk.word_tokenize(nlp_sentence)\n",
    "parser = ChartParser(nlp_grammar)\n",
    "\n",
    "try: \n",
    "    parses = list(parser.parse(words))\n",
    "    if parses:\n",
    "        parse_tree = parses[0]\n",
    "        print(\"Parse Tree: \")\n",
    "        print(parse_tree)\n",
    "        for tree in parser.parse(sentence.split()):\n",
    "            print(tree, \"\\n\")\n",
    "            tree.pretty_print()\n",
    "            \n",
    "        print(\"\\nExtracted Information:\")\n",
    "        extract_information(parse_tree)\n",
    "    else:\n",
    "        print(\"No parse tree found\")\n",
    "        \n",
    "except nltk.parse.api.ParserError as e:\n",
    "    print(f\"Error during parsing {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 10 : Dependency Parsing with Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted Dependency Parse Tree:\n",
      "Elon --compound-- Musk (PROPN)\n",
      "Musk --nsubj-- founded (PROPN)\n",
      "founded --ROOT-- founded (VERB)\n",
      "SpaceX --dobj-- founded (PROPN)\n",
      ", --punct-- founded (PUNCT)\n",
      "and --cc-- founded (CCONJ)\n",
      "the --det-- headquarters (DET)\n",
      "headquarters --nsubj-- are (NOUN)\n",
      "are --conj-- founded (AUX)\n",
      "in --prep-- are (ADP)\n",
      "Palo --compound-- Alto (PROPN)\n",
      "Alto --pobj-- in (PROPN)\n",
      ". --punct-- are (PUNCT)\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "\n",
    "def extract_named_entities_and_parse_tree(sentence):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    print(\"Formatted Dependency Parse Tree:\")\n",
    "    for token in doc:\n",
    "        print(f\"{token.text} --{token.dep_}-- {token.head.text} ({token.pos_})\")\n",
    "        \n",
    "def main():\n",
    "    sentence = \"Elon Musk founded SpaceX, and the headquarters are in Palo Alto.\"\n",
    "    named_entities = extract_named_entities_and_parse_tree(sentence)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elon --compound-- Musk (PROPN)\n",
      "Musk --nsubj-- founded (VERB)\n",
      "founded --ROOT-- founded (VERB)\n",
      "SpaceX --dobj-- founded (VERB)\n",
      ", --punct-- founded (VERB)\n",
      "and --cc-- founded (VERB)\n",
      "the --det-- headquarters (NOUN)\n",
      "headquarters --nsubj-- are (AUX)\n",
      "are --conj-- founded (VERB)\n",
      "in --prep-- are (AUX)\n",
      "Palo --compound-- Alto (PROPN)\n",
      "Alto --pobj-- in (ADP)\n",
      ". --punct-- are (AUX)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "def dependency_sparint(text):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    for token in doc:\n",
    "        print(f\"{token.text} --{token.dep_}-- {token.head.text} ({token.head.pos_})\")\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    sentence = \"Elon Musk founded SpaceX, and the headquarters are in Palo Alto.\"\n",
    "    dependency_sparint(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 11 : Name Entitiy Recognition (NER) with SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted Dependency Parse Tree:\n",
      "Elon --compound-- Musk (PROPN)\n",
      "Musk --nsubj-- founded (PROPN)\n",
      "founded --ROOT-- founded (VERB)\n",
      "SpaceX --dobj-- founded (PROPN)\n",
      ", --punct-- founded (PUNCT)\n",
      "and --cc-- founded (CCONJ)\n",
      "the --det-- headquarters (DET)\n",
      "headquarters --nsubj-- are (NOUN)\n",
      "are --conj-- founded (AUX)\n",
      "in --prep-- are (ADP)\n",
      "Palo --compound-- Alto (PROPN)\n",
      "Alto --pobj-- in (PROPN)\n",
      ". --punct-- are (PUNCT)\n",
      "\n",
      "Extracted Named Entities:\n",
      "Presons:  ['Elon Musk']\n",
      "Organizations:  []\n",
      "Locations:  ['Palo Alto']\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "\n",
    "def extract_named_entities_and_parse_tree(sentence):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(sentence)\n",
    "\n",
    "    named_entities = {\n",
    "        \"persons\": [ent.text for ent in doc.ents if ent.label_ == \"PERSON\"],\n",
    "        \"locations\": [ent.text for ent in doc.ents if ent.label_ == \"GPE\"],\n",
    "        \"organizations\": [ent.text for ent in doc.ents if ent.label_ == \"ORG\"]\n",
    "    }\n",
    "    \n",
    "    print(\"Formatted Dependency Parse Tree:\")\n",
    "    for token in doc:\n",
    "        print(f\"{token.text} --{token.dep_}-- {token.head.text} ({token.pos_})\")\n",
    "        \n",
    "    return named_entities\n",
    "\n",
    "def main():\n",
    "    sentence = \"Elon Musk founded SpaceX, and the headquarters are in Palo Alto.\"\n",
    "    named_entities = extract_named_entities_and_parse_tree(sentence)\n",
    "    \n",
    "    print(\"\\nExtracted Named Entities:\")\n",
    "    print(\"Presons: \", named_entities[\"persons\"])\n",
    "    print(\"Organizations: \", named_entities[\"organizations\"])\n",
    "    print(\"Locations: \", named_entities[\"locations\"])\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorized Named Entities:\n",
      "PERSON: Barack Obama, Neil Armstrong, Leonardo da Vinci\n",
      "GPE: Hawaii, Paris\n",
      "DATE: 2008, 1969\n",
      "LAW: the Affordable Care Act, Apollo 11\n",
      "ORDINAL: first\n",
      "CARDINAL: one, one\n",
      "WORK_OF_ART: The Mona Lisa\n",
      "ORG: the Louvre Museum\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"\"\"\n",
    "    Barack Obama was born in Hawaii. He was elected president in 2008.\n",
    "    During his presidency, he implemented various policies, including the Affordable Care Act.\n",
    "    \n",
    "    In 1969, Neil Armstrong was the first person to walk on the moon as part of the Apollo 11 mission.\n",
    "    He famously said, \"That's one small step for [a] man, one giant leap for mankind.\"\n",
    "    \n",
    "    The Mona Lisa, painted by Leonardo da Vinci, is house in the Louvre Museum in Paris.\n",
    "    It is one of the most famous and valuable pieces of art in the world.\n",
    "\"\"\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "categories = {}\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ not in categories:\n",
    "        categories[ent.label_] = []\n",
    "    categories[ent.label_].append(ent.text)\n",
    "    \n",
    "print(\"Categorized Named Entities:\")\n",
    "for label, entities in categories.items():\n",
    "    print(f\"{label}: {', '.join(entities)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: I love to eat pizza\n",
      "Token: I, POS: PRON, Dependency: nsubj\n",
      "Token: love, POS: VERB, Dependency: ROOT\n",
      "Token: to, POS: PART, Dependency: aux\n",
      "Token: eat, POS: VERB, Dependency: xcomp\n",
      "Token: pizza, POS: NOUN, Dependency: dobj\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"e206ec5515cb484bb77e564da6528096-0\" class=\"displacy\" width=\"550\" height=\"237.0\" direction=\"ltr\" style=\"max-width: none; height: 237.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">I</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">love</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"250\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"250\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">eat</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"450\">pizza</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"450\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e206ec5515cb484bb77e564da6528096-0-0\" stroke-width=\"2px\" d=\"M62,102.0 62,85.33333333333333 147.0,85.33333333333333 147.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e206ec5515cb484bb77e564da6528096-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M62,104.0 L58,96.0 66,96.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e206ec5515cb484bb77e564da6528096-0-1\" stroke-width=\"2px\" d=\"M262,102.0 262,85.33333333333333 347.0,85.33333333333333 347.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e206ec5515cb484bb77e564da6528096-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M262,104.0 L258,96.0 266,96.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e206ec5515cb484bb77e564da6528096-0-2\" stroke-width=\"2px\" d=\"M162,102.0 162,68.66666666666666 350.0,68.66666666666666 350.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e206ec5515cb484bb77e564da6528096-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M350.0,104.0 L354.0,96.0 346.0,96.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e206ec5515cb484bb77e564da6528096-0-3\" stroke-width=\"2px\" d=\"M362,102.0 362,85.33333333333333 447.0,85.33333333333333 447.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e206ec5515cb484bb77e564da6528096-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M447.0,104.0 L451.0,96.0 443.0,96.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: the cat sleeps on the sofa\n",
      "Token: the, POS: DET, Dependency: det\n",
      "Token: cat, POS: NOUN, Dependency: nsubj\n",
      "Token: sleeps, POS: VERB, Dependency: ROOT\n",
      "Token: on, POS: ADP, Dependency: prep\n",
      "Token: the, POS: DET, Dependency: det\n",
      "Token: sofa, POS: NOUN, Dependency: pobj\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"976513f3a23648c3888de9c253c20595-0\" class=\"displacy\" width=\"650\" height=\"237.0\" direction=\"ltr\" style=\"max-width: none; height: 237.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">cat</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"250\">sleeps</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"250\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">on</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"450\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"450\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"550\">sofa</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"550\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-976513f3a23648c3888de9c253c20595-0-0\" stroke-width=\"2px\" d=\"M62,102.0 62,85.33333333333333 147.0,85.33333333333333 147.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-976513f3a23648c3888de9c253c20595-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M62,104.0 L58,96.0 66,96.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-976513f3a23648c3888de9c253c20595-0-1\" stroke-width=\"2px\" d=\"M162,102.0 162,85.33333333333333 247.0,85.33333333333333 247.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-976513f3a23648c3888de9c253c20595-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M162,104.0 L158,96.0 166,96.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-976513f3a23648c3888de9c253c20595-0-2\" stroke-width=\"2px\" d=\"M262,102.0 262,85.33333333333333 347.0,85.33333333333333 347.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-976513f3a23648c3888de9c253c20595-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M347.0,104.0 L351.0,96.0 343.0,96.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-976513f3a23648c3888de9c253c20595-0-3\" stroke-width=\"2px\" d=\"M462,102.0 462,85.33333333333333 547.0,85.33333333333333 547.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-976513f3a23648c3888de9c253c20595-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M462,104.0 L458,96.0 466,96.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-976513f3a23648c3888de9c253c20595-0-4\" stroke-width=\"2px\" d=\"M362,102.0 362,68.66666666666666 550.0,68.66666666666666 550.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-976513f3a23648c3888de9c253c20595-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M550.0,104.0 L554.0,96.0 546.0,96.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: she dances well at parties\n",
      "Token: she, POS: PRON, Dependency: nsubj\n",
      "Token: dances, POS: VERB, Dependency: ROOT\n",
      "Token: well, POS: ADV, Dependency: advmod\n",
      "Token: at, POS: ADP, Dependency: prep\n",
      "Token: parties, POS: NOUN, Dependency: pobj\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"668a445df1b24a0a969c0dd046e48944-0\" class=\"displacy\" width=\"550\" height=\"237.0\" direction=\"ltr\" style=\"max-width: none; height: 237.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">she</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">dances</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"250\">well</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"250\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">at</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"450\">parties</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"450\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-668a445df1b24a0a969c0dd046e48944-0-0\" stroke-width=\"2px\" d=\"M62,102.0 62,85.33333333333333 147.0,85.33333333333333 147.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-668a445df1b24a0a969c0dd046e48944-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M62,104.0 L58,96.0 66,96.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-668a445df1b24a0a969c0dd046e48944-0-1\" stroke-width=\"2px\" d=\"M162,102.0 162,85.33333333333333 247.0,85.33333333333333 247.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-668a445df1b24a0a969c0dd046e48944-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M247.0,104.0 L251.0,96.0 243.0,96.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-668a445df1b24a0a969c0dd046e48944-0-2\" stroke-width=\"2px\" d=\"M162,102.0 162,68.66666666666666 350.0,68.66666666666666 350.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-668a445df1b24a0a969c0dd046e48944-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M350.0,104.0 L354.0,96.0 346.0,96.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-668a445df1b24a0a969c0dd046e48944-0-3\" stroke-width=\"2px\" d=\"M362,102.0 362,85.33333333333333 447.0,85.33333333333333 447.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-668a445df1b24a0a969c0dd046e48944-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M447.0,104.0 L451.0,96.0 443.0,96.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: he reads books in the library\n",
      "Token: he, POS: PRON, Dependency: nsubj\n",
      "Token: reads, POS: VERB, Dependency: ROOT\n",
      "Token: books, POS: NOUN, Dependency: dobj\n",
      "Token: in, POS: ADP, Dependency: prep\n",
      "Token: the, POS: DET, Dependency: det\n",
      "Token: library, POS: NOUN, Dependency: pobj\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"53b72d1b025448af88c7687bf7f873a1-0\" class=\"displacy\" width=\"650\" height=\"237.0\" direction=\"ltr\" style=\"max-width: none; height: 237.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">he</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">reads</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"250\">books</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"250\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"450\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"450\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"550\">library</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"550\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-53b72d1b025448af88c7687bf7f873a1-0-0\" stroke-width=\"2px\" d=\"M62,102.0 62,85.33333333333333 147.0,85.33333333333333 147.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-53b72d1b025448af88c7687bf7f873a1-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M62,104.0 L58,96.0 66,96.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-53b72d1b025448af88c7687bf7f873a1-0-1\" stroke-width=\"2px\" d=\"M162,102.0 162,85.33333333333333 247.0,85.33333333333333 247.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-53b72d1b025448af88c7687bf7f873a1-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M247.0,104.0 L251.0,96.0 243.0,96.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-53b72d1b025448af88c7687bf7f873a1-0-2\" stroke-width=\"2px\" d=\"M162,102.0 162,68.66666666666666 350.0,68.66666666666666 350.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-53b72d1b025448af88c7687bf7f873a1-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M350.0,104.0 L354.0,96.0 346.0,96.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-53b72d1b025448af88c7687bf7f873a1-0-3\" stroke-width=\"2px\" d=\"M462,102.0 462,85.33333333333333 547.0,85.33333333333333 547.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-53b72d1b025448af88c7687bf7f873a1-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M462,104.0 L458,96.0 466,96.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-53b72d1b025448af88c7687bf7f873a1-0-4\" stroke-width=\"2px\" d=\"M362,102.0 362,68.66666666666666 550.0,68.66666666666666 550.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-53b72d1b025448af88c7687bf7f873a1-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M550.0,104.0 L554.0,96.0 546.0,96.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "nlp_sentences = [\n",
    "    \"I love to eat pizza\",\n",
    "    \"the cat sleeps on the sofa\",\n",
    "    \"she dances well at parties\",\n",
    "    \"he reads books in the library\"\n",
    "]\n",
    "\n",
    "for sentence in nlp_sentences:\n",
    "    doc = nlp(sentence)\n",
    "    print(\"Sentence:\", sentence)\n",
    "    \n",
    "    for token in doc:\n",
    "        print(f\"Token: {token.text}, POS: {token.pos_}, Dependency: {token.dep_}\")\n",
    "    \n",
    "    # Visualization of the dependency parse tree\n",
    "    spacy.displacy.render(doc, style=\"dep\", options={'compact': True, 'distance': 100})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
